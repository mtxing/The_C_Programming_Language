Prior works on improving speech quality with visual input typically study each type of auditory distortion separately (e.g., separation, inpainting, video-to-speech) and
present tailored algorithms. This paper proposes to unify
these subjects and study Generalized Speech Enhancement,
where the goal is not to reconstruct the exact reference
clean signal, but to focus on improving certain aspects
of speech. In particular, this paper concerns intelligibility, quality, and video synchronization. We cast the
problem as audio-visual speech resynthesis, which is composed of two steps: pseudo audio-visual speech recognition
(P-AVSR) and pseudo text-to-speech synthesis (P-TTS). PAVSR and P-TTS are connected by discrete units derived
from a self-supervised speech model. Moreover, we utilize
self-supervised audio-visual speech model to initialize PAVSR. The proposed model is coined ReVISE. ReVISE is
the first high-quality model for in-the-wild video-to-speech
synthesis and achieves superior performance on all LRS3